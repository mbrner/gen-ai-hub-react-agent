{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2565c978-ddc3-4da7-880e-5316096db97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U \"generative-ai-hub-sdk>=3.1\" tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21011229-2573-45ec-bc28-c11fe5493f53",
   "metadata": {},
   "source": [
    "# ReAct Agent From Scratch Using SAP's Generative AI Hub"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae5e0963-061e-4949-a3e0-3a9fea70fb10",
   "metadata": {},
   "source": [
    "We are going to build a [ReAct Agent](https://arxiv.org/abs/2210.03629) without using any AI Agent framework. We are going to use the generative AI hub's **Orchestration service** to do the LLM calls.\n",
    "\n",
    "![Screenshot taken from ](./orchestration_service.png)\n",
    "\n",
    "The Orchestration service will help you to design robust AI workflows, connecting diverse components like data pipelines, AI models, and prebuilt modules (grounding, content filtering, and more), and gain peace of mind with less maintenance. Focus on innovation, not integration, and bring your AI vision to life faster. Learn more about the Orchestation service [here](https://help.sap.com/docs/sap-ai-core/sap-ai-core-service-guide/orchestration-workflow).\n",
    "\n",
    "The Orchestration service provides access to all LLMs available on the Generative AI Hub through a harmonize API. This API allows the integration of both proprietary and open source models, providing a unified interface for an ever growing and changing model landscape.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4994d8d0-785b-4e66-8146-d883e1a16067",
   "metadata": {},
   "source": [
    "#### Create an Orchestration Deployment\n",
    "\n",
    "To use orchestration, we need to create a deployment for it in AI Core.\n",
    "\n",
    "The following code will check your instance for an existing deployment, and if none is found, create one and wait for it to become available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8414d1c-5341-4571-be7b-c756ce62ecad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, Type, Union, Dict, Any, List, Callable\n",
    "from gen_ai_hub.proxy import get_proxy_client\n",
    "from typing import Callable\n",
    "from ai_core_sdk.ai_core_v2_client import AICoreV2Client\n",
    "from ai_api_client_sdk.models.status import Status\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "client = get_proxy_client()\n",
    "\n",
    "def spinner(check_callback: Callable, timeout: int = 300, check_every_n_seconds: int = 10):\n",
    "    start = time.time()\n",
    "    last_check = start\n",
    "    while time.time() - start < timeout:\n",
    "        now = time.time()\n",
    "        if now - start > timeout:\n",
    "            break\n",
    "        if now - last_check > check_every_n_seconds:\n",
    "            return_value = check_callback()\n",
    "            if return_value:\n",
    "                return return_value\n",
    "        for char in '|/-\\\\':\n",
    "            clear_output(wait=True)  # Clears the output to show a fresh update\n",
    "            print(f'Waiting for the deployment to become ready... {char}')\n",
    "            time.sleep(0.2)  # Adjust the speed as needed\n",
    "\n",
    "\n",
    "def retrieve_or_deploy_orchestration(ai_core_client: AICoreV2Client,\n",
    "                                     scenario_id: str = \"orchestration\",\n",
    "                                     executable_id: str = \"orchestration\",\n",
    "                                     config_suffix: str = \"simple\",\n",
    "                                     start_timeout: int = 300):\n",
    "    if not config_suffix:\n",
    "        raise ValueError(\"Empty `config_suffix` not allowed\")\n",
    "    deployments = ai_core_client.deployment.query(\n",
    "        scenario_id=scenario_id,\n",
    "        executable_ids=[executable_id],\n",
    "        status=Status.RUNNING\n",
    "    )\n",
    "    if deployments.count > 0:\n",
    "        return sorted(deployments.resources, key=lambda x: x.start_time)[0]\n",
    "    config_name = f\"{config_suffix}-orchestration\"\n",
    "    configs = ai_core_client.configuration.query(\n",
    "        scenario_id=scenario_id,\n",
    "        executable_ids=[executable_id],\n",
    "        search=config_name\n",
    "    )\n",
    "    if configs.count > 0:\n",
    "        config = sorted(deployments.resources, key=lambda x: x.start_time)[0]\n",
    "    else:\n",
    "        config = ai_core_client.configuration.create(\n",
    "            scenario_id=scenario_id,\n",
    "            executable_id=executable_id,\n",
    "            name=config_name,\n",
    "        )\n",
    "    deployment = ai_core_client.deployment.create(configuration_id=config.id)\n",
    "\n",
    "    def check_ready():\n",
    "        updated_deployment = ai_core_client.deployment.get(deployment.id)\n",
    "        return None if updated_deployment.status != Status.RUNNING else updated_deployment\n",
    "    \n",
    "    return spinner(check_ready)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28a9423-793b-4b3e-80c0-6daa4ad75819",
   "metadata": {},
   "source": [
    "#### Helper Function to run LLM requests\n",
    "\n",
    "We will define a simple helper function that accepts a prompt template, model name and values for the placeholders in the prompt template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fc080e-9135-44ae-b338-ac92d9770951",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "import yaml\n",
    "\n",
    "from gen_ai_hub.proxy import get_proxy_client\n",
    "from ai_api_client_sdk.models.status import Status\n",
    "\n",
    "from gen_ai_hub.orchestration.models.config import OrchestrationConfig\n",
    "from gen_ai_hub.orchestration.models.llm import LLM\n",
    "from gen_ai_hub.orchestration.models.message import SystemMessage, UserMessage\n",
    "from gen_ai_hub.orchestration.models.template import Template, TemplateValue\n",
    "from gen_ai_hub.orchestration.models.content_filter import AzureContentFilter\n",
    "from gen_ai_hub.orchestration.service import OrchestrationService\n",
    "\n",
    "client = get_proxy_client()\n",
    "deployment = retrieve_or_deploy_orchestration(client.ai_core_client)\n",
    "orchestration_service = OrchestrationService(api_url=deployment.deployment_url, proxy_client=client)\n",
    "\n",
    "def send_request(prompt, _print=False, _model='meta--llama3-70b-instruct', **kwargs):\n",
    "    config = OrchestrationConfig(\n",
    "        llm=LLM(name=_model, parameters={\"temperature\": 0}),\n",
    "        template=Template(messages=[UserMessage(prompt)])\n",
    "    )\n",
    "    template_values = [TemplateValue(name=key, value=value) for key, value in kwargs.items()]\n",
    "    answer = orchestration_service.run(config=config, template_values=template_values)\n",
    "    result = answer.module_results.llm.choices[0].message.content \n",
    "    if _print:\n",
    "        formatted_prompt = answer.module_results.templating[0].content\n",
    "        print(f\"<-- PROMPT --->\\n{formatted_prompt if _print else prompt}\\n<--- RESPONSE --->\\n{result}\")  \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0979590a-b90c-4f1d-93fc-b10951720c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"Write a haiku about {{?topic}}\"\n",
    "\n",
    "_ = send_request(template, topic=\"SAP Devtover\", _print=True, _model='meta--llama3-70b-instruct')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583f009d-f5ca-4065-864d-cd505e917ad9",
   "metadata": {},
   "source": [
    "## Building a ReAct Agent from Scratch\n",
    "\n",
    "We need to define tools for the agent. To simplify this we will write a helper class that extracts the name of the tool, description and input schema from a python function definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f5555f-eeb7-4b40-baba-4b91f81b8a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Callable\n",
    "import json\n",
    "\n",
    "@dataclass\n",
    "class ToolInfo:\n",
    "    name: str\n",
    "    description: str\n",
    "    schema: dict\n",
    "\n",
    "    @classmethod\n",
    "    def from_callable(cls, func: Callable):\n",
    "        # Get the function's name\n",
    "        func_name = func.__name__\n",
    "        # Get the function's docstring, default to an empty string if it's None\n",
    "        func_description = func.__doc__ or \"\"\n",
    "        # Get the function's type annotations\n",
    "        annotations = func.__annotations__\n",
    "        # Filter out any arguments without a type annotation\n",
    "        schema = {k: str(v) for k, v in annotations.items() if k != 'return'}\n",
    "        # Return an instance of ToolInfo with the extracted name, description, and schema\n",
    "        return cls(name=func_name, description=func_description, schema=schema)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Tool: {self.name}\\nUsage Info: {self.description}\\nSchema: {self.schema}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643e91c9-d064-4112-8972-675fd1bfbac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds two numbers.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "print(str(ToolInfo.from_callable(add)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce9afc2-563c-4a36-82ed-96220d31bbdf",
   "metadata": {},
   "source": [
    "The key component of the ReAct agent is the prompt.\n",
    "We need to instruct the model to follow the `Thought -> Action -> Observation`flow, informing the model about the tools and how to use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf21175-3fee-49fd-be16-abc19d078cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "REACT_PROMPT = \"\"\"Respond to the human as helpfully and accurately as possible. You are an agent that gets a set of tools and can use these tools in actions.\n",
    "\n",
    "The goal is to provide an answer to the query of the user. To find the correct answer you can use tools. As input your are given the user query and steps already taken.\n",
    "Your response should always follow the pattern shown below. You in your response you have to fill ... with actual output. Text in [] is to explain what kind of output is expected.\n",
    "\n",
    "--- start: response format in case of an action---\n",
    "Thought: ... [Your though on what to do next]\n",
    "Action:\n",
    "```\n",
    "... [A json blob describing the next action]\n",
    "```\n",
    "Observation: [always finish with \"Observation\" to trigger the execution of the action and to see the result]\n",
    "--- end: response format in case of an action---\n",
    "If you don't have to use a tool because you know the final answer instead of specifying an Action, give the final Answer like this:\n",
    "--- start: response format to provide the final answer---\n",
    "Thought: ... [Your though on what to do next]\n",
    "Final Answer: the final answer to the original input question\n",
    "--- end: response format to provide the final answer---\n",
    "\n",
    "You have access to the following tools:\n",
    "\n",
    "{{?tools}}\n",
    "\n",
    "Use a json blob to specify a tool by providing an \"name\" key (tool name) and an \"input\" key (tool input).\n",
    "Provide only ONE action per json, as shown:\n",
    "--- start: json blob ---\n",
    "{\n",
    "  \"name\": ... [Name of the tool, valid tools, are: {{?tool_names}}]\n",
    "  \"input\": ... [Arguments of the tool, expected schemas of the tools are listed above]\n",
    "}\n",
    "--- end: json blob ---\n",
    "You can't use comments in the json blob.\n",
    "\n",
    "\n",
    "To recap follow this format:\n",
    "\n",
    "--- start: recap ---\n",
    "User Query: ... [input query to answer]\n",
    "Thought: ... [your thoughts on the action to take]\n",
    "Action:\n",
    "```\n",
    "{\n",
    "  \"name\": ... [Name of the tool, valid tools, are: {{?tool_names}}]\n",
    "  \"input\": ... [Arguments of the tool, expected schemas of the tools are listed above]\n",
    "}\n",
    "```\n",
    "Observation: ... [Result of the action]\n",
    "\n",
    "... [repeat Thought/Action/Observation N times]\n",
    "\n",
    "Thought: I know what to respond\n",
    "Action:\n",
    "```\n",
    "{\n",
    "  \"name\": \"finish\",\n",
    "  \"input\": {\n",
    "      \"answer\": ... [The final answer to return the result of exeucting the to plan to answer the original input. Using the \"finish\" tool is the only way to finish the conversation.]\n",
    "  }\n",
    "}\n",
    "```\n",
    "--- end: recap ---\n",
    "\n",
    "Begin! Always start your response with \"Thought\" and finish by an Action + json blob with key \"name\" and \"input\". No text outside that schema. Only one Action per response. Never give an Observation as part of your response.\n",
    "\n",
    "User Query: {{?query}}\n",
    "\n",
    "{{?scratchpad}}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573c8176-ee1e-47bc-8313-fdcf6e1b7110",
   "metadata": {},
   "source": [
    "Now we need the code that:\n",
    "1. Calls the LLM\n",
    "2. Parses the response\n",
    "3. Executes the tools\n",
    "4. Triggers the next agent loop is not finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4b826f-6394-4c08-8a69-0d6a2861fae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions to parse the response and append observation to the response\n",
    "import re\n",
    "\n",
    "def extract_and_parse_json(text):\n",
    "    # Use regex to find text encapsulated within ``` ... ``` or ```json ... ```blocks\n",
    "    pattern = r\"```(?:json)?\\s*(.*?)```\"\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    \n",
    "    if match:\n",
    "        json_text = match.group(1).strip()\n",
    "        try:\n",
    "            # Parse the extracted JSON-like text\n",
    "            parsed_json = json.loads(json_text)\n",
    "            return parsed_json\n",
    "        except json.JSONDecodeError:\n",
    "            raise ValueError(f\"Invalid JSON format: {text}\")\n",
    "    else:\n",
    "        return ValueError(f\"No JSON found in text: {text}\")\n",
    "\n",
    "def append_for_scratchpad(input_text: str, value: str, suffix: str = \"Observation: \") -> str:\n",
    "    # Split the input text by lines\n",
    "    lines = input_text.splitlines()\n",
    "    last_line = lines[-1]\n",
    "    desired_line = f\"{suffix}{value}\"\n",
    "    for c_exisiting, c_wanted in zip(last_line, desired_line):\n",
    "        if c_exisiting != c_wanted:\n",
    "            return f\"{input_text}\\n{desired_line}\"\n",
    "    return f\"{input_text}{desired_line[len(last_line):]}\"\n",
    "\n",
    "def print_scratchpad(scratchpad):\n",
    "    for i, step in enumerate(scratchpad):\n",
    "        print(f\"\\x1b[31m >>> STEP {i+1} <<< \\x1b[0m\" + f\"\\n{step}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f173cb-7b66-41c6-885b-621e81fae535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool to return the final answer\n",
    "class FinalAnswer(Exception):\n",
    "    def __init__(self, text: str, *args, **kwargs):\n",
    "        self.text = text\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "def finish(answer: str) -> str:\n",
    "    \"\"\"Give the final answer to the user query.\"\"\"\n",
    "    raise FinalAnswer(text=answer) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130284b3-886c-434b-a554-9d42c7e6f78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "\n",
    "class ReactAgent:\n",
    "    def __init__(self, tools: List[Callable], model='meta--llama3-70b-instruct'):\n",
    "        self.model = model\n",
    "        self.tools = {}\n",
    "        self.tool_names = []\n",
    "        self.tool_descriptions = []\n",
    "        for tool in tools + [finish]: # always add the finish tool\n",
    "            tool_info = ToolInfo.from_callable(tool)\n",
    "            self.tool_names.append(tool_info.name)\n",
    "            self.tool_descriptions.append(str(tool_info))\n",
    "            self.tools[tool_info.name] = tool\n",
    "    \n",
    "    \n",
    "    def run(self, query: str, max_turns: int = 20):\n",
    "        scratchpad = []\n",
    "        turns = 0\n",
    "        while True and turns < max_turns:\n",
    "            response = send_request(\n",
    "                REACT_PROMPT,\n",
    "                _model=self.model,\n",
    "                _print=False,\n",
    "                query=query,\n",
    "                scratchpad=\"\\n\".join(scratchpad),\n",
    "                tools=\"\\n\\n\".join(self.tool_descriptions),\n",
    "                tool_names=\", \".join(self.tool_names)\n",
    "            )\n",
    "            try:\n",
    "                action = extract_and_parse_json(response)\n",
    "                observation = str(self.tools[action[\"name\"]](**action[\"input\"]))\n",
    "            except FinalAnswer as answer:\n",
    "                scratchpad.append(append_for_scratchpad(response, answer.text))\n",
    "                return answer.text, scratchpad\n",
    "            except Exception as e:\n",
    "                observation = \"Error when calling the tool\" + \"\\n\".join(traceback.format_exc().splitlines()[-10:])\n",
    "            scratchpad.append(append_for_scratchpad(response, observation))\n",
    "            turns += 1\n",
    "        return None, scratchpad          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bbd48e-715a-49be-b799-081433530c16",
   "metadata": {},
   "source": [
    "Now, let's test the agent.\n",
    "\n",
    "As is well known, LLMs often struggle with even simple mathematical calculations. Therefore, we will provide our agent with tools for addition, subtraction, multiplication, and division."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d62e5e9-d690-47f3-b0e7-0ef6f45a28a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds two numbers.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "def subtract(a: int, b: int) -> int:\n",
    "    \"\"\"Subtract two numbers.\"\"\"\n",
    "    return a - b\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "def divide(a: int, b: int) -> int:\n",
    "    \"\"\"Divide two numbers.\"\"\"\n",
    "    return a / b\n",
    "\n",
    "agent = ReactAgent([add, multiply, subtract, divide])\n",
    "res, scratchpad = agent.run(\"What is 5+5*2-10?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889a78df-055a-4b5c-88af-9b5d934885ab",
   "metadata": {},
   "source": [
    "Let us take a look at the scratchpad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca2e0ad-599b-4972-8bc3-0f30568516d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_scratchpad(scratchpad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7890542-510a-4ad5-a7f9-5eb544d42dce",
   "metadata": {},
   "source": [
    "Elementary school math is a bit lame, let us make our agent smarter and prevent halluciation by adding a Wikipedia search tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f2df54-e88e-4679-8c9c-fbe605b0bd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Util that calls Wikipedia.\"\"\"\n",
    "from typing import Any, Optional\n",
    "import logging\n",
    "import wikipedia\n",
    "\n",
    "WIKIPEDIA_MAX_QUERY_LENGTH = 300\n",
    "\n",
    "class WikipediaAPIWrapper:\n",
    "    \"\"\"Wrapper around WikipediaAPI.\n",
    "\n",
    "    This wrapper will use the Wikipedia API to conduct searches and\n",
    "    fetch page summaries. By default, it will return the page summaries\n",
    "    of the top-k results. It limits the content by doc_content_chars_max.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, top_k_results=3, lang=\"en\", doc_content_chars_max=1000):\n",
    "        \"\"\"Initialize WikipediaAPIWrapper with optional parameters.\"\"\"\n",
    "        self.top_k_results = top_k_results\n",
    "        self.doc_content_chars_max = doc_content_chars_max\n",
    "        wikipedia.set_lang(lang)\n",
    "\n",
    "    def wiki_search(self, query: str) -> str:\n",
    "        \"\"\"Perform a Wikipedia search and retrieve page summaries.\n",
    "        Good queries are for specific people, places, etc . things that have existing articles in the lexicon, rather than responding to questions.\"\"\"\n",
    "        try:\n",
    "            page_titles = wikipedia.search(query[:WIKIPEDIA_MAX_QUERY_LENGTH], results=self.top_k_results)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error searching Wikipedia: {e}\")\n",
    "            return \"Error occurred during Wikipedia search.\"\n",
    "\n",
    "        summaries = []\n",
    "        for page_title in page_titles[:self.top_k_results]:\n",
    "            wiki_page = self._fetch_page(page_title)\n",
    "            if wiki_page:\n",
    "                summary = self._formatted_page_summary(page_title, wiki_page)\n",
    "                if summary:\n",
    "                    summaries.append(summary)\n",
    "\n",
    "        if not summaries:\n",
    "            return \"No good Wikipedia Search Result was found\"\n",
    "\n",
    "        return \"\\n\\n\".join(summaries)[:self.doc_content_chars_max]\n",
    "\n",
    "    @staticmethod\n",
    "    def _formatted_page_summary(page_title: str, wiki_page: Any) -> Optional[str]:\n",
    "        return f\"Page: {page_title}\\nSummary: {wiki_page.summary}\"\n",
    "\n",
    "    @staticmethod\n",
    "    def _fetch_page(page_title: str) -> Optional[Any]:\n",
    "        \"\"\"Fetch the Wikipedia page.\"\"\"\n",
    "        try:\n",
    "            return wikipedia.page(title=page_title, auto_suggest=False)\n",
    "        except (wikipedia.exceptions.PageError, wikipedia.exceptions.DisambiguationError):\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4dd2d1-52e4-4a50-97bb-35d4bb32d207",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_wrapper = WikipediaAPIWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9819cdb6-96c5-45d2-a7f0-104ebc67489e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_wrapper.wiki_search(\"SAP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efeaa00-4874-4406-949d-0193d955dbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"What is ([Age of barack obama] * 1000) / ([SAP founding year] - [Age of Taylor Swift] - 437)?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1712fd2-750d-4e18-a1a2-fac06de9c144",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(send_request(task))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3e00db-81f4-4f31-90ec-fce2a7da8934",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ReactAgent([add, multiply, subtract, divide, wiki_wrapper.wiki_search])\n",
    "res, scratchpad = agent.run(task)\n",
    "print_scratchpad(scratchpad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0290cd32-9d17-4390-8ef3-8bf995f8230f",
   "metadata": {},
   "source": [
    "and we can add more tools!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ebc74d-e1ba-4e21-82bf-b7bef775a441",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def today():\n",
    "    \"\"\"Get today's time in isoformat.\"\"\"\n",
    "    return datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1b3d37-d51d-42b9-83d7-0e10865f2a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ReactAgent([add, multiply, subtract, divide, today, wiki_wrapper.wiki_search])\n",
    "res, scratchpad = agent.run(task)\n",
    "print_scratchpad(scratchpad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e901e9b8-53dd-4fce-8b52-521ebf813eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "res, scratchpad = agent.run(\"How many days ago was the 2024 Super Bowl? Spend some thoughts on own to do proper calculations with dates.\")\n",
    "print_scratchpad(scratchpad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80d09a8-0d51-4c45-b94a-f34898189054",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
